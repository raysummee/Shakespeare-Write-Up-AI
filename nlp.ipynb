{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "nlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5028687f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "5028687f",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82e8ac37"
      },
      "source": [
        "import tensorflow as tf\n",
        "# from tensorflow.python.compiler.mlcompute import mlcompute\n",
        "# mlcompute.set_mlc_device(device_name='any')\n"
      ],
      "id": "82e8ac37",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b89cc3f"
      },
      "source": [
        "path_to_file = 'shakespeare.txt'"
      ],
      "id": "4b89cc3f",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a29ac2a"
      },
      "source": [
        "text = open(path_to_file, 'r').read()"
      ],
      "id": "4a29ac2a",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "f5ced5c5",
        "outputId": "75278ca9-31d7-4a37-9e55-e8b7c177207c"
      },
      "source": [
        "text[:500]"
      ],
      "id": "f5ced5c5",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d14c412"
      },
      "source": [
        "vocab = sorted(set(text))"
      ],
      "id": "9d14c412",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15012b06",
        "outputId": "e745234d-14a7-4204-9b33-6fc9add4e6f9"
      },
      "source": [
        "len(vocab)"
      ],
      "id": "15012b06",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82cb91fc"
      },
      "source": [
        ""
      ],
      "id": "82cb91fc",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38503035"
      },
      "source": [
        "# for pair in enumerate(vocab):\n",
        "#     print(pair)"
      ],
      "id": "38503035",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b02bd376"
      },
      "source": [
        "char_to_ind = {char:ind for ind, char in enumerate(vocab)}"
      ],
      "id": "b02bd376",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37769935",
        "outputId": "4895ed55-9360-4315-82a8-4e16ab57152c"
      },
      "source": [
        "char_to_ind['H']"
      ],
      "id": "37769935",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd674682"
      },
      "source": [
        "index_to_char = np.array(vocab)"
      ],
      "id": "bd674682",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "a5b40019",
        "outputId": "47b1cc5e-eb44-44fd-bafc-7f3f0c050612"
      },
      "source": [
        "index_to_char[33]"
      ],
      "id": "a5b40019",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'H'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fc178bf"
      },
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ],
      "id": "6fc178bf",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fcd51a8",
        "outputId": "094b1981-cd39-4e53-90a2-0bcd73a8d6a5"
      },
      "source": [
        "encoded_text.shape"
      ],
      "id": "2fcd51a8",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5445609,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627d05ea"
      },
      "source": [
        ""
      ],
      "id": "627d05ea",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "255026cf",
        "outputId": "3dd94245-138c-408d-8109-cb8c6e48ec72"
      },
      "source": [
        "print(text[:500])"
      ],
      "id": "255026cf",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a444ec2b"
      },
      "source": [
        "line = \"From fairest creatures we desire increase,\""
      ],
      "id": "a444ec2b",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12161026",
        "outputId": "6cc404bb-9226-4741-980b-ca0bd2fe8830"
      },
      "source": [
        "len(line)"
      ],
      "id": "12161026",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ca1c59d"
      },
      "source": [
        "lines = '''\n",
        "From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\n",
        "'''"
      ],
      "id": "3ca1c59d",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9caeb5f7",
        "outputId": "44db793c-b30a-473c-8f60-edbdcac26e1f"
      },
      "source": [
        "len(lines)"
      ],
      "id": "9caeb5f7",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a3a986f"
      },
      "source": [
        "seq_len = 120"
      ],
      "id": "8a3a986f",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d829bd8e"
      },
      "source": [
        "tota_num_seq = len(text) // (seq_len+1)"
      ],
      "id": "d829bd8e",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89116241",
        "outputId": "1b636da6-e449-4e3c-c1b7-74b2703bde4b"
      },
      "source": [
        "tota_num_seq"
      ],
      "id": "89116241",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ac2058"
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "id": "b1ac2058",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31db9f7a",
        "outputId": "4de1e155-eefb-4a43-96ef-103ac8360596"
      },
      "source": [
        "type(char_dataset)"
      ],
      "id": "31db9f7a",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d6fcf7e"
      },
      "source": [
        "# for item in char_dataset.take(500):\n",
        "#     print(index_to_char[item.numpy()])"
      ],
      "id": "3d6fcf7e",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4be8b1e"
      },
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ],
      "id": "e4be8b1e",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0b30306"
      },
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_text = seq[:-1]\n",
        "    target_text = seq[1:]\n",
        "    return input_text, target_text"
      ],
      "id": "d0b30306",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b48b7a6e"
      },
      "source": [
        "datasets = sequences.map(create_seq_targets)"
      ],
      "id": "b48b7a6e",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83a5cc55",
        "outputId": "7ffbf335-f62d-4868-a4c0-a90a58a2e58a"
      },
      "source": [
        "for input_text, target_text in datasets.take(1):\n",
        "    print(input_text.numpy())\n",
        "    print(\"\".join(index_to_char[input_text.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_text.numpy())\n",
        "    print(\"\".join(index_to_char[target_text.numpy()]))"
      ],
      "id": "83a5cc55",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a24e4c98"
      },
      "source": [
        "batch_size = 128"
      ],
      "id": "a24e4c98",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8a1b940"
      },
      "source": [
        "buffer_size = 10000\n",
        "datasets = datasets.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "id": "f8a1b940",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8cd0858",
        "outputId": "1a266535-5732-48e2-ea1e-7b358d09b04d"
      },
      "source": [
        "datasets"
      ],
      "id": "c8cd0858",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46270c84"
      },
      "source": [
        ""
      ],
      "id": "46270c84",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c539dbf"
      },
      "source": [
        "vocab_size = len(vocab)"
      ],
      "id": "2c539dbf",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "071119e4"
      },
      "source": [
        "embed_dim = 64"
      ],
      "id": "071119e4",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9e7752c"
      },
      "source": [
        "rnn_neurons = 1026"
      ],
      "id": "e9e7752c",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b450e0bc"
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "id": "b450e0bc",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eca51e3c"
      },
      "source": [
        "def sparse_cat_loss(y_true, y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ],
      "id": "eca51e3c",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bb4d5cc"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding"
      ],
      "id": "6bb4d5cc",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f159efb"
      },
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
        "    model.add(GRU(rnn_neurons, return_sequences=True,stateful=True, recurrent_initializer='glorot_uniform'))\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
        "    return model"
      ],
      "id": "5f159efb",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a797115d"
      },
      "source": [
        "model = create_model(vocab_size=vocab_size, embed_dim=embed_dim, rnn_neurons=rnn_neurons, batch_size=batch_size)"
      ],
      "id": "a797115d",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d1742bd",
        "outputId": "f7f01afa-b6dc-4d48-ff60-6a7be642f1b0"
      },
      "source": [
        "model.summary()"
      ],
      "id": "0d1742bd",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 64)           5376      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (128, None, 1026)         3361176   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 84)           86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4a4aac8"
      },
      "source": [
        ""
      ],
      "id": "e4a4aac8",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75efd799"
      },
      "source": [
        "for input_example_batch, target_example_batch in datasets.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)"
      ],
      "id": "75efd799",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "888b71b2",
        "outputId": "9b922301-0f4d-4150-cbcc-d749085275c2"
      },
      "source": [
        "example_batch_predictions.shape"
      ],
      "id": "888b71b2",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 120, 84])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a15ae80d"
      },
      "source": [
        "sample_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ],
      "id": "a15ae80d",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57081ee2"
      },
      "source": [
        "sample_indices = tf.squeeze(sample_indices, axis=-1).numpy()"
      ],
      "id": "57081ee2",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a64c1f37",
        "outputId": "a822ca98-d8b3-4431-d3d9-6f64549a5bac"
      },
      "source": [
        "sample_indices"
      ],
      "id": "a64c1f37",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([47,  6, 66, 69, 54, 80, 11, 51, 18, 46, 83, 52, 58, 24, 30,  0, 63,\n",
              "        1, 30, 74, 26, 32, 22, 42, 66,  4, 66, 35, 58, 40, 48, 20, 14, 15,\n",
              "       67, 11, 71, 28, 13, 26, 59, 11, 62, 28, 49, 47, 62, 28, 52, 54, 42,\n",
              "       42, 41, 31, 19, 27, 27,  0, 43, 43, 21, 82, 12, 82, 78,  0, 65, 67,\n",
              "       54, 28, 83, 27, 36, 63, 75, 53, 82, 73, 32, 77, 56, 21, 68, 77, 56,\n",
              "       74,  4, 17, 30, 68, 52, 62,  5,  3, 70, 19, 31, 82, 11, 56, 64,  9,\n",
              "       33, 43, 17,  4, 72, 51, 69, 25,  3, 54, 77, 38, 74, 65, 42, 25, 17,\n",
              "       72])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "040fe134",
        "outputId": "f06860a7-1bcd-470f-da76-c517a0aa9497"
      },
      "source": [
        "index_to_char[sample_indices]"
      ],
      "id": "040fe134",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['V', '(', 'k', 'n', '_', 'y', '0', 'Z', '7', 'U', '}', '[', 'c',\n",
              "       '>', 'E', '\\n', 'h', ' ', 'E', 's', 'A', 'G', ';', 'Q', 'k', '&',\n",
              "       'k', 'J', 'c', 'O', 'W', '9', '3', '4', 'l', '0', 'p', 'C', '2',\n",
              "       'A', 'd', '0', 'g', 'C', 'X', 'V', 'g', 'C', '[', '_', 'Q', 'Q',\n",
              "       'P', 'F', '8', 'B', 'B', '\\n', 'R', 'R', ':', '|', '1', '|', 'w',\n",
              "       '\\n', 'j', 'l', '_', 'C', '}', 'B', 'K', 'h', 't', ']', '|', 'r',\n",
              "       'G', 'v', 'a', ':', 'm', 'v', 'a', 's', '&', '6', 'E', 'm', '[',\n",
              "       'g', \"'\", '\"', 'o', '8', 'F', '|', '0', 'a', 'i', '-', 'H', 'R',\n",
              "       '6', '&', 'q', 'Z', 'n', '?', '\"', '_', 'v', 'M', 's', 'j', 'Q',\n",
              "       '?', '6', 'q'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ebf1ac0"
      },
      "source": [
        "epochs = 30"
      ],
      "id": "0ebf1ac0",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5b87c0c"
      },
      "source": [
        "# temp = list(datasets.as_numpy_iterator())"
      ],
      "id": "b5b87c0c",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c354f93"
      },
      "source": [
        ""
      ],
      "id": "8c354f93",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ea4516",
        "outputId": "30cc5a7c-75b7-47f9-a2db-b944cc3e7932"
      },
      "source": [
        "model.fit(datasets, epochs=epochs)"
      ],
      "id": "72ea4516",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "351/351 [==============================] - 48s 129ms/step - loss: 2.5500\n",
            "Epoch 2/30\n",
            "351/351 [==============================] - 49s 137ms/step - loss: 1.7656\n",
            "Epoch 3/30\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 1.4913\n",
            "Epoch 4/30\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.3613\n",
            "Epoch 5/30\n",
            "351/351 [==============================] - 50s 138ms/step - loss: 1.2919\n",
            "Epoch 6/30\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 1.2487\n",
            "Epoch 7/30\n",
            "351/351 [==============================] - 49s 137ms/step - loss: 1.2180\n",
            "Epoch 8/30\n",
            "351/351 [==============================] - 50s 139ms/step - loss: 1.1936\n",
            "Epoch 9/30\n",
            "351/351 [==============================] - 48s 134ms/step - loss: 1.1724\n",
            "Epoch 10/30\n",
            "351/351 [==============================] - 50s 139ms/step - loss: 1.1546\n",
            "Epoch 11/30\n",
            "351/351 [==============================] - 49s 137ms/step - loss: 1.1382\n",
            "Epoch 12/30\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.1238\n",
            "Epoch 13/30\n",
            "351/351 [==============================] - 49s 136ms/step - loss: 1.1108\n",
            "Epoch 14/30\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 1.0978\n",
            "Epoch 15/30\n",
            "351/351 [==============================] - 50s 139ms/step - loss: 1.0855\n",
            "Epoch 16/30\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.0741\n",
            "Epoch 17/30\n",
            "351/351 [==============================] - 50s 139ms/step - loss: 1.0633\n",
            "Epoch 18/30\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.0532\n",
            "Epoch 19/30\n",
            "351/351 [==============================] - 50s 139ms/step - loss: 1.0433\n",
            "Epoch 20/30\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.0346\n",
            "Epoch 21/30\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 1.0254\n",
            "Epoch 22/30\n",
            "351/351 [==============================] - 50s 138ms/step - loss: 1.0177\n",
            "Epoch 23/30\n",
            "351/351 [==============================] - 48s 134ms/step - loss: 1.0102\n",
            "Epoch 24/30\n",
            "351/351 [==============================] - 50s 139ms/step - loss: 1.0040\n",
            "Epoch 25/30\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 0.9981\n",
            "Epoch 26/30\n",
            "351/351 [==============================] - 50s 138ms/step - loss: 0.9924\n",
            "Epoch 27/30\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 0.9873\n",
            "Epoch 28/30\n",
            "351/351 [==============================] - 49s 138ms/step - loss: 0.9827\n",
            "Epoch 29/30\n",
            "351/351 [==============================] - 50s 139ms/step - loss: 0.9788\n",
            "Epoch 30/30\n",
            "351/351 [==============================] - 48s 134ms/step - loss: 0.9755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3cfe303350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93e87f72"
      },
      "source": [
        "# model.save(\"nlp.h5\")"
      ],
      "id": "93e87f72",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8538217"
      },
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "model.load_weights('nlp.h5')\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "id": "c8538217",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAebwt3bmhDT",
        "outputId": "acc09354-6d84-4f7d-d85b-e4b00a9712a6"
      },
      "source": [
        "model.summary()"
      ],
      "id": "pAebwt3bmhDT",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 84)             86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUYbjxoZniPk"
      },
      "source": [
        "def generate_text(model, start_seed,gen_size=500, temp=1.0):\n",
        "  num_generate = gen_size\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  temperature = temp\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(index_to_char[predicted_id])\n",
        "  return start_seed + \"\".join(text_generated)\n"
      ],
      "id": "cUYbjxoZniPk",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9d-XUqlqqPj",
        "outputId": "2ab1d52c-29f9-4535-9c00-73ad53f9bfd5"
      },
      "source": [
        "print(generate_text(model, \"JULIET\", gen_size=1000))"
      ],
      "id": "R9d-XUqlqqPj",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JULIETHIUS. She comes from his behalf take up resolve.\n",
            "  OLIVIA. I will, my sword. Know, my lord,\n",
            "    I cannot ever since my painful man,\n",
            "    And there to save with likewise which\n",
            "    Wept bargains, and how his grasping hand in him,\n",
            "    Will put it up to argusy good creation; but\n",
            "    My little bed-world's ntstance keep\n",
            "    The reading and indusicatique to us! Mistress May,  \n",
            "    Let me be rough to fear content I would,\n",
            "    And gave them not to sleep. My house to brave,\n",
            "    Read not the soul upon your Grace becomes yellven\n",
            "    For Thesess, miracles!\n",
            "  GLOUCESTER. I get so oft that horse the one might commend.\n",
            "  SEBASTIAN. I had. Then the Moon'st article I have destroy'd,\n",
            "    Balifous any in my mountaines better,\n",
            "    Even to myself wants, and raise departure,\n",
            "    And the weak ragged thanks I do excuse\n",
            "    You would have tongue?\n",
            "  DEMETRIUS. Shame got we be lack'd\n",
            "    even hollowed thy face.\n",
            "  COSTARD. Grandam, what needs there.\n",
            "  THURIO. Then thou art daggers! Hence!         Descends.\n",
            "\n",
            "  Pob. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smURW5sPq41S"
      },
      "source": [
        ""
      ],
      "id": "smURW5sPq41S",
      "execution_count": null,
      "outputs": []
    }
  ]
}